\chapter{نتایج}

\section{مقدمه}
در این فصل، ابتدا محیط پیاده‌سازی روش‌های محاسباتی مورد استفاده در این پژوهش معرفی می‌شود. سپس، ابرپارامترهای مربوط به هر یک از روش‌ها تشریح خواهد شد. در ادامه، روش‌های مختلف به‌کاررفته در این پژوهش تعریف شده و نتایج حاصل از به‌کارگیری معماری‌های گوناگون شبکه‌های عصبی گرافی، شامل شبکه عصبی گرافی پیچشی، شبکه عصبی گرافی مبتنی بر سازوکار توجه و شبکه عصبی گرافی مجهز به سازوکار پرش دانش، بر روی مجموعه‌داده \lr{PPI} گزارش می‌گردد. 
در گام بعدی، نتایج مربوط به انواع توابع فعال‌سازی مورد بررسی و تحلیل قرار می‌گیرد. در ادامه، روش پیشنهادی بر اساس آزمایش‌های انجام‌شده و همچنین تأثیر تعیین آستانه به‌صورت بازه‌ای مورد ارزیابی قرار گرفته و در نهایت، نتایج نهایی با پژوهش‌های پیشین در زمینه کشف ماژول‌های عملکردی در شبکه‌های \lr{PPI} مقایسه می‌شود.

\section{محیط پیاده‌سازی}

در پیاده‌سازی روش‌های محاسباتی این پژوهش، از زبان برنامه‌نویسی پایتون نسخه 12.3 استفاده شده است. به‌منظور خواندن و پردازش فایل‌های مربوط به هستی‌شناسی ژن، کتابخانه \lr{goatools} به‌کار گرفته شده و پیاده‌سازی الگوریتم‌های یادگیری و شبکه‌های عصبی گرافی با استفاده از کتابخانه‌های \lr{torch} و \lr{torch-geometric} انجام شده است. همچنین، تعبیه‌های مربوط به عبارات \lr{GO} که از الگوریتم \lr{Node2Vec} حاصل شده‌اند، به کمک کتابخانه \lr{gensim} بارگذاری شده‌اند. 

برای ایجاد و نمایش گراف‌ها، از کتابخانه‌های \lr{NetworkX} و \lr{Matplotlib} استفاده شده است. در نهایت، برای تابع هزینه پایه، از پیاده‌سازی ارائه‌شده در پژوهش \lr{NOCD} که در مخزن گیت‌هاب این پروژه\LTRfootnote{github.com/shchur/overlapping-community-detection} در دسترس است بهره گرفته شده و بردارهای تعبیه مربوط به هستی‌شناسی ژن نیز از مخزن گیت‌هاب پروژه \lr{go-node2vec}\LTRfootnote{github.com/marcopodda/go-node2vec} استخراج و مورد استفاده قرار گرفته‌اند. در جدول \ref{table:python-libraries} اطلاعات مربوط به نسخه هر یک از این کتابخانه‌ها ذکر شده‌اند.

\begin{table}[h]
	\centering
	\caption{اطلاعات مربوط به کتابخانه‌های استفاده شده و نسخه هر یک}
	\label{table:python-libraries}
	\vspace{3mm}
	\begin{tabular}{| c | c |}
		\hline
		کتابخانه & نسخه \\
		\hline
		torch & 2.5.1 \\
		torch-geometric & 2.6.1 \\
		pandas & 2.2.3 \\
		numpy & 1.26.4 \\
		goatools & 1.4.12 \\
		gensim & 4.3.3 \\
		networkx & 3.4.2 \\
		matplotlib & 3.9.2 \\
		\hline

	\end{tabular}
\end{table}

\section{نتایج مربوط به عملکرد شبکه‌های عصبی گرافی}

در این بخش، عملکرد دو معماری پرکاربرد شبکه‌های عصبی گرافی شامل \lr{GCN} و \lr{GAT} در مسئله شناسایی ماژول‌های عملکردی مورد ارزیابی و مقایسه قرار می‌گیرد. هدف از این بررسی، تحلیل تأثیر نوع معماری و پیرنگ‌های مختلف تابع هزینه بر کیفیت خوشه‌بندی در شبکه‌های \lr{PPI} است.

کلیه آزمایش‌ها تحت مجموعه‌ای از شرایط یکسان انجام شده‌اند. در تمامی پیرنگ‌ها، ویژگی‌های ورودی به‌صورت دودویی بوده و شامل زیرهستی‌شناسی‌های فرآیندهای زیستی و عملکرد مولکولی می‌باشند. تعداد لایه‌های شبکه در تمامی آزمایش‌ها برابر با ۲ در نظر گرفته شده و در معماری \lr{GAT}، تعداد سرهای توجه برابر با ۴ تنظیم شده است. همچنین، مطابق با چارچوب روش \lr{NOCD}، آستانه تشخیص عضویت همپوشان برابر با 3.0 انتخاب شده است. سایر ابرپارامترهای آموزش شامل نرخ یادگیری\LTRfootnote{Learning Rate}($10^{-4}$)، بهینه‌ساز \lr{Adam} در تمامی آزمایش‌ها ثابت نگه داشته شده‌اند تا امکان مقایسه منصفانه بین روش‌ها فراهم شود.

پیرنگ‌های مورد بررسی در این بخش، مبتنی بر نسخه‌های مختلف تابع هزینه \lr{NOCD} بوده و شامل موارد زیر هستند:
\begin{itemize}
	\item تابع هزینه \lr{NOCD} که در پژوهش \cite{nocd2019} معرفی شده‌ است.
	\item نسخه بهبود‌یافته و وزن‌دار تابع \lr{NOCD} که به‌عنوان یکی از نوآوری‌های این پژوهش با هدف مدل‌سازی دقیق‌تر شدت تعاملات معرفی شده است.
	\item نسخه مبتنی بر همسایگی مرتبه بالاتر تابع \lr{NOCD} که با در نظر گرفتن ساختار غیرمحلی شبکه‌های \lr{PPI}، در این پژوهش پیشنهاد شده است.
\end{itemize}

برای هر یک از معماری‌های \lr{GCN} و \lr{GAT}، تمامی پیرنگ‌های فوق به‌صورت مستقل ارزیابی شده‌اند. نتایج حاصل بر اساس معیارهای دقت، بازیابی، امتیاز \lr{F1} و صحت مورد مقایسه قرار گرفته و در جداول \ref{table:collins_result}، \ref{table:krogan_result} و \ref{table:DIP_result} ارائه شده‌اند.

این آزمایش‌ها بر روی سه مجموعه‌داده \lr{Collins}، \lr{Krogan-Core} و \lr{DIP} انجام شده است. با توجه به اندازه بزرگ‌تر و تعداد بیشتر پروتئین‌ها و تعاملات در مجموعه‌داده \lr{DIP}، فرآیند آموزش در این مجموعه نیازمند تعداد ایپاک‌های بیشتری بوده و برابر با ۵۰۰۰ ایپاک در نظر گرفته شده است، در حالی که برای دو مجموعه‌داده دیگر آموزش شبکه‌ها پس از ۲۰۰۰ ایپاک همگرا شده‌اند. این تفاوت در تعداد ایپاک‌ها به‌منظور دستیابی به همگرایی پایدار در شبکه‌های بزرگ‌تر اعمال شده است. همچنین، به‌منظور انتخاب پیکربندی بهینه ماژول‌های شناسایی‌شده در هر پیرنگ، از معیار ماژولاریتی به‌عنوان یک شاخص ارزیابی کمکی در فرآیند انتخاب مدل استفاده شده است.

\begin{table}[h]
	\centering
	\caption{نتایج عملکرد شبکه عصبی و تابع هزینه برای مجموعه داده \lr{Collins}}
	\label{table:collins_result}
	\vspace{3mm}
	\resizebox{\textwidth}{!}{
		\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
			\hline
			\textbf{شبکه عصبی} & \textbf{تابع هزینه} & \boldsymbol{\lambda} &  \textbf{\lr{Precision}} & \textbf{\lr{Recall}} & \textbf{\lr{F1}} & \textbf{\lr{Accuracy}} & \textbf{\lr{NCP}} & \textbf{\lr{NCB}}
			\\
			\hline
			\lr{GCN} & \lr{NOCD} & تعریف نشده & 891.0 & 337.0 & 489.0 & 252.0 & 49 & 187 \\
			\lr{GCN} & \lr{NOCD} وزن‌دار & تعریف نشده & 687.0 & 695.0 & 691.0 & 326.0 & 167 & 385 \\
			\lr{GCN} & \lr{NOCD} مرتبه بالاتر & 5.0 & 818.0 & 316.0 & 456.0 & 254.0 & 54 & 175 \\
			\lr{GCN} & \lr{NOCD} مرتبه بالاتر & 1 & 662.0 & 212.0 & 322.0 & 245.0 & 49 & 118 \\
			
			\lr{GAT} & \lr{NOCD} & تعریف نشده & 825.0 & 522.0 & 640.0 & 295.0 & 156 & 289 \\
			\lr{GAT} & \lr{NOCD} وزن‌دار & تعریف نشده & 879.0 & 630.0 & 734.0 & 292.0 & 240 & 349 \\
			\lr{GAT} & \lr{NOCD} مرتبه بالاتر & 5.0 & 880.0 & 525.0 & 658.0 & 282.0 & 161 & 291 \\
			\lr{GAT} & \lr{NOCD} مرتبه بالاتر & 1 & 916.0 & 381.0 & 538.0 & 276.0 & 186 & 211 \\
			\hline 
			
		\end{tabular}
	}
	
\end{table} 


\begin{table}[h]
	\centering
	\caption{نتایج عملکرد شبکه عصبی و تابع هزینه برای مجموعه داده \lr{Krogan-Core}}
	\label{table:krogan_result}
	\vspace{3mm}
	\resizebox{\textwidth}{!}{
		\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
			\hline
			\textbf{شبکه عصبی} & \textbf{تابع هزینه} & \boldsymbol{\lambda} &  \textbf{\lr{Precision}} & \textbf{\lr{Recall}} & \textbf{\lr{F1}} & \textbf{\lr{Accuracy}} & \textbf{\lr{NCP}} & \textbf{\lr{NCB}}
			\\
			\hline
			\lr{GCN} & \lr{NOCD} & تعریف نشده & 435.0 & 555.0 & 488.0 & 290.0 & 141 & 333 \\
			\lr{GCN} & \lr{NOCD} وزن‌دار & تعریف نشده & 478.0 & 603.0 & 533.0 & 294.0 & 153 & 362 \\
			\lr{GCN} & \lr{NOCD} مرتبه بالاتر & 5.0 & 504.0 & 428.0 & 463.0 & 265.0 & 123 & 257 \\
			\lr{GCN} & \lr{NOCD} مرتبه بالاتر & 1 & 632.0 & 373.0 & 469.0 & 251.0 & 117 & 224 \\
			
			\lr{GAT} & \lr{NOCD} & تعریف نشده & 598.0 & 543.0 & 569.0 & 257.0 & 238 & 326 \\
			\lr{GAT} & \lr{NOCD} وزن‌دار & تعریف نشده & 655.0 & 605.0 & 629.0 & 261.0 & 266 & 363 \\
			\lr{GAT} & \lr{NOCD} مرتبه بالاتر & 5.0 & 514.0 & 360.0 & 423.0 & 243.0 & 187 & 216 \\
			\lr{GAT} & \lr{NOCD} مرتبه بالاتر & 1 & 308.0 & 220.0 & 257.0 & 205.0 & 122 & 132 \\
			\hline 
			
		\end{tabular}
	}
	
\end{table} 


\begin{table}[h]
	\centering
	\caption{نتایج عملکرد شبکه عصبی و تابع هزینه برای مجموعه داده \lr{DIP}}
	\label{table:DIP_result}
	\vspace{3mm}
	\resizebox{\textwidth}{!}{
		\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
			\hline
			\textbf{شبکه عصبی} & \textbf{تابع هزینه} & \boldsymbol{\lambda} &  \textbf{\lr{Precision}} & \textbf{\lr{Recall}} & \textbf{\lr{F1}} & \textbf{\lr{Accuracy}} & \textbf{\lr{NCP}} & \textbf{\lr{NCB}}
			\\
			\hline
			\lr{GCN} & \lr{NOCD} & تعریف نشده & 1 & 2 & 3 & 4 & 5 & 6 \\
			\lr{GCN} & \lr{NOCD} وزن‌دار & تعریف نشده & 1 & 2 & 3 & 4 & 5 & 6 \\
			\lr{GCN} & \lr{NOCD} مرتبه بالاتر & 5.0 & 1 & 2 & 3 & 4 & 5 & 6 \\
			\lr{GCN} & \lr{NOCD} مرتبه بالاتر & 1 & 1 & 2 & 3 & 4 & 5 & 6 \\
			
			\lr{GAT} & \lr{NOCD} & تعریف نشده & 343.0 & 390.0 & 365.0 & 244.0 & 153 & 302 \\
			\lr{GAT} & \lr{NOCD} وزن‌دار & تعریف نشده & 1 & 2 & 3 & 4 & 5 & 6 \\
			\lr{GAT} & \lr{NOCD} مرتبه بالاتر & 5.0 & 144.0 & 076.0 & 100.0 & 193.0 & 22 & 59 \\
			\lr{GAT} & \lr{NOCD} مرتبه بالاتر & 1 & 1 & 2 & 3 & 4 & 5 & 6 \\
			\hline 
			
		\end{tabular}
	}
	
\end{table} 
